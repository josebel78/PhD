{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/josebel78/03MIAR_Algoritmos-de-Optimizacion/blob/main/Algoritmos_Jose_Belenguer_AG3_reto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljZMs2rg93q6"
   },
   "source": [
    "# PhD-Paper-01-Cal\n",
    "## José Belenguer Ballester\n",
    "### GitHub repository:\n",
    "#### https://github.com/josebel78/PhD.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-gbxt9BFfdN"
   },
   "source": [
    "## MODULE IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qP-Y3Gkfc4vn"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHRiJhTnFmuV"
   },
   "source": [
    "## DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_dependencies():\n",
    "\n",
    "    # def arrange_dependencies()\n",
    "        \n",
    "    global dep_lists\n",
    "\n",
    "    # A list of lists (dep_listss) is created from dep_dash to store the interdependencies:\n",
    "        # In the simplest case, every item (list) will contain two elements: dep_job, prec_job\n",
    "        # In more complex situations, every item (list) will contain multiple elements: dep_job, prec_job_1, prec_job_2...\n",
    "    \n",
    "    dep_lists = []\n",
    "    \n",
    "    for dep_job,prec_job in dep_dash.items():\n",
    "\n",
    "        dep_job_in_dash = [dep_job in sublist for sublist in dep_lists]\n",
    "        prec_job_in_dash = [prec_job in sublist for sublist in dep_lists]        \n",
    "\n",
    "        if any(dep_job_in_dash) and any(prec_job_in_dash):\n",
    "            prec_job_in_dash_idx = prec_job_in_dash.index(True)\n",
    "            prec_job_in_dash_sublist = dep_lists.pop(prec_job_in_dash_idx)\n",
    "            dep_job_in_dash_idx = dep_job_in_dash.index(True)\n",
    "            dep_lists[dep_job_in_dash_idx].extend(prec_job_in_dash_sublist)\n",
    "        elif any(dep_job_in_dash):\n",
    "            dep_job_in_dash_idx = dep_job_in_dash.index(True)\n",
    "            dep_lists[dep_job_in_dash_idx].append(prec_job)\n",
    "        elif any(prec_job_in_dash):\n",
    "            prec_job_in_dash_idx = prec_job_in_dash.index(True)\n",
    "            dep_lists[prec_job_in_dash_idx].insert(0, dep_job)\n",
    "        else:\n",
    "            dep_lists.append([dep_job, prec_job])\n",
    "\n",
    "    sublist_idx = 0\n",
    "    # dependency_dict = {}\n",
    "\n",
    "    while sublist_idx < len(dep_lists):\n",
    "        dep_job = dep_lists[sublist_idx][0]\n",
    "        prec_job = dep_lists[sublist_idx][-1]\n",
    "        dep_job_in_dash = [dep_job in sublist for sublist in dep_lists[sublist_idx+1:]]\n",
    "        prec_job_in_dash = [prec_job in sublist for sublist in dep_lists[sublist_idx+1:]]\n",
    "        if any(dep_job_in_dash):\n",
    "            dep_job_sublist = dep_lists.pop(sublist_idx)\n",
    "            dep_job_in_dash_idx = dep_job_in_dash.index(True)\n",
    "            dep_lists[dep_job_in_dash_idx].extend(dep_job_sublist[1:])\n",
    "        elif any(prec_job_in_dash):\n",
    "            prec_job_in_dash_idx = prec_job_in_dash.index(True)\n",
    "            prec_job_in_dash_sublist = dep_lists.pop(prec_job_in_dash_idx)\n",
    "            dep_lists[sublist_idx].extend(prec_job_in_dash_sublist[1:])\n",
    "        else:\n",
    "            sublist_idx += 1\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_instance(file_name):\n",
    "        \n",
    "    global J, M, Rmax, dep_dash\n",
    "    \n",
    "    with open(file_name,\"r\") as file:\n",
    "        data = file.readlines()\n",
    "    \n",
    "    # PROBLEM SPECIFICATIONS: Line #1: number of machines (M), and of jobs (J)\n",
    "    specs = data[0].split()\n",
    "    J = int(specs[0])\n",
    "    M = int(specs[1])\n",
    "\n",
    "    machine_names = data[1].split()[0::2]\n",
    "\n",
    "    prec_lines = len(data) - (J+1)*2 - 2 # Number of lines for precedences in the instance file\n",
    "\n",
    "    dep_dash = {}\n",
    "\n",
    "    # PROCESSING TIMES: lines # 2 ... 2+J-1\n",
    "    skiprows_times = 1\n",
    "    skipfooter_times = prec_lines + (J + 3)\n",
    "    processing_times_df = pd.read_csv(file_name,\n",
    "                                      sep=\"\\s+\",\n",
    "                                      header=None,\n",
    "                                      names=machine_names,\n",
    "                                      index_col=False,\n",
    "                                      usecols=list(range(1,2*M,2)),\n",
    "                                      dtype=np.int8,\n",
    "                                      engine='python',\n",
    "                                      skiprows=skiprows_times,\n",
    "                                      skipfooter=skipfooter_times\n",
    "                                     )\n",
    "\n",
    "    # RESOURCES: lines # 2 + J ... 2 * (J + 1)\n",
    "    skiprows_res = J + 2\n",
    "    skipfooter_res = prec_lines + 2\n",
    "    resources_df = pd.read_csv(file_name,\n",
    "                               sep=\"\\s+\",\n",
    "                               header=None,\n",
    "                               names=machine_names,\n",
    "                               index_col=False,\n",
    "                               usecols=list(range(1,2*M,2)),\n",
    "                               dtype=np.int8,\n",
    "                               engine='python',\n",
    "                               skiprows=skiprows_res,\n",
    "                               skipfooter=skipfooter_res\n",
    "                              )\n",
    "    \n",
    "    Rmax = int(data[(J+1)*2 + 1])\n",
    "    \n",
    "    # PRECEDENCES: lines # 2 + J ... 2 * (J + 1)\n",
    "    if prec_lines > 1: # If 1 then 'Precedence' would be an empty field\n",
    "        prec_array = np.full(shape=(J,), fill_value=None)\n",
    "        for p in range(len(data)-prec_lines+1,len(data)):\n",
    "            prec_line = data[p]\n",
    "            prec_line = prec_line.split(':')\n",
    "            prec_array[int(prec_line[0])] = int(prec_line[1])\n",
    "            dep_dash.update({int(prec_line[0]) : int(prec_line[1])})\n",
    "        arrange_dependencies()\n",
    "\n",
    "    problem_df = pd.concat([processing_times_df, resources_df, pd.Series(prec_array)], axis=1, join='outer', copy=False)    \n",
    "    \n",
    "    # instance_name = instance.rstrip('.txt')\n",
    "    # # print(f'\\nInstance specifications: J = {J} jobs, M = {M} machines, prec = {prec_lines-1} precedence relationship(s), and Rmax = {Rmax} resources.')\n",
    "    # print(f'\\n\\n# {instance_name}: J = {J} jobs, M = {M} machines, prec = {prec_lines-1} precedence relationship(s), and Rmax = {Rmax} resources.')\n",
    "\n",
    "    return problem_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA STRUCTURING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job:\n",
    "    def __init__(self, index, p_times, res, prec):\n",
    "        self.index = int(index) # Index (name) of the job as an int\n",
    "        self.p_times = p_times # Processing times on each machine as a NumPy array of float\n",
    "        self.res = res # Job resources on each machine as a NumPy array of float\n",
    "        self.prec = prec # Previous job (with a precedence relation) as an int\n",
    "        self.cost = np.empty(shape=(M,), dtype=np.int8) # Job cost on each machine derived from the assignment rule as a NumPy array\n",
    "        # self.cost = int(0) # Job's assigned cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine:\n",
    "    def __init__(self, index):\n",
    "        self.index = int(index) # Index (name) of the machine as an int\n",
    "        self.job_seq = np.empty(shape=(0)) #, dtype=np.int8) # Job sequence on the machine as a NumPy array\n",
    "        self.job_times = np.empty(shape=(0), dtype=np.int8) # Job processing time on the machine as a NumPy array\n",
    "        self.s_times = np.empty(shape=(0), dtype=np.int8) # Job processing time on the machine as a NumPy array\n",
    "        self.e_times = np.empty(shape=(0), dtype=np.int8) # Job processing time on the machine as a NumPy array\n",
    "        self.t_spans = {}\n",
    "        self.job_res = np.empty(shape=(0), dtype=np.int8) # Job resources on the machine at every instant as a NumPy array\n",
    "        self.C = int(0) # Machine makespan as an int\n",
    "        \n",
    "    def reset(self):\n",
    "        self.job_seq = np.empty(shape=(0)) #, dtype=np.int8) # Job sequence on the machine as a NumPy array\n",
    "        self.job_times = np.empty(shape=(0), dtype=np.int8) # Job processing time on the machine as a NumPy array\n",
    "        self.s_times = np.empty(shape=(0), dtype=np.int8) # Job processing time on the machine as a NumPy array\n",
    "        self.e_times = np.empty(shape=(0), dtype=np.int8) # Job processing time on the machine as a NumPy array\n",
    "        self.t_spans.clear()\n",
    "        self.job_res = np.empty(shape=(0), dtype=np.int8) # Job resources on the machine as a NumPy array\n",
    "        self.C = int(0) # Machine makespan as an int\n",
    "        \n",
    "    def program_job(self, job, pos=-1):\n",
    "        # Every parameter's length will be:\n",
    "            # s_times, e_times, job_times, job_seq: J\n",
    "            # job_res: C-1\n",
    "        if pos == -1:\n",
    "            job_s_time = int(0) if (self.job_seq.size == 0) else int(self.C)\n",
    "            job_e_time = job_s_time + job.p_times[self.index]\n",
    "            self.s_times = np.append(self.s_times, job_s_time)\n",
    "            self.e_times = np.append(self.e_times, job_e_time)\n",
    "            self.job_times = np.append(self.job_times, job.p_times[self.index])\n",
    "            self.job_res = np.append(self.job_res, job.res[self.index]*np.ones(shape=(job.p_times[self.index],)))\n",
    "            self.job_seq = np.append(self.job_seq, job)\n",
    "        else:\n",
    "            job_s_time = int(0) if (self.job_seq.size == 0) else int(self.s_times[pos])\n",
    "            job_e_time = job_s_time + job.p_times[self.index]\n",
    "            self.s_times = np.concatenate((self.s_times[:pos], \n",
    "                                           np.array([job_s_time]), \n",
    "                                           self.s_times[pos:] + job.p_times[self.index]))\n",
    "            self.e_times = np.concatenate((self.e_times[:pos], \n",
    "                                           np.array([job_e_time]), \n",
    "                                           self.e_times[pos:] + job.p_times[self.index]))\n",
    "            self.job_times = np.concatenate((self.job_times[:pos], \n",
    "                                             np.array([job.p_times[self.index]]), \n",
    "                                             self.job_times[pos:]))\n",
    "            self.job_res = np.concatenate((self.job_res[:job_s_time], \n",
    "                                             job.res[self.index]*np.ones(shape=(job.p_times[self.index],)), \n",
    "                                             self.job_res[job_s_time:]))\n",
    "            self.job_seq = np.concatenate((self.job_seq[:pos], \n",
    "                                           np.array([job]), \n",
    "                                           self.job_seq[pos:]))\n",
    "        self.t_spans.clear()\n",
    "        for j in range(len(self.job_seq)):\n",
    "            self.t_spans.update({self.job_seq[j].index: (self.s_times[j], self.e_times[j])})\n",
    "        self.C = self.e_times[-1] # Machine makespan as an int\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jobs(problem_df):\n",
    "    \n",
    "    # def create_jobs(problem_df):\n",
    "        # It creates the problem's job list.\n",
    "        # It returns a list of objects of the job class which are constructed by reading the corresponding information from the problem_df\n",
    "    \n",
    "    job_list = []\n",
    "\n",
    "    for j in range(J):\n",
    "        p_times = np.array(list(problem_df.iloc[j,:M]))\n",
    "        res = np.array(list(problem_df.iloc[j,M:2*M]))\n",
    "        prec = int(problem_df.iloc[j,2*M]) if isinstance(problem_df.iloc[j,2*M], int) else problem_df.iloc[j,2*M] # Precedent job nº; otherwise, None\n",
    "        job = Job(j, p_times, res, prec)\n",
    "        job_list.append(job)\n",
    "\n",
    "    return job_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_machines(num_machines):\n",
    "    \n",
    "    # def create_machines(num_machines):\n",
    "        # It creates the problem's machine list.\n",
    "        # It returns a list of objects of the mach class which are constructed by reading the corresponding information from the problem_df   \n",
    "    \n",
    "    machine_list = [Machine(m) for m in range(num_machines)]\n",
    "\n",
    "    return machine_list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_solution(solution):\n",
    "    \n",
    "    # Display of a solution\n",
    "    \n",
    "    for machine in solution:\n",
    "        print(f'\\nMachine M{machine.index}:')\n",
    "        print(f'Job sequence: \\t\\t {[job.index for job in machine.job_seq]}')\n",
    "        print(f'Start times: \\t\\t {machine.s_times}')\n",
    "        print(f'Processing times: \\t {machine.job_times}')\n",
    "        print(f'End times: \\t\\t {machine.e_times}')\n",
    "        print(f'Resources: \\t\\t {machine.job_res}')\n",
    "        print(f'Makespan: \\t\\t C = {machine.C}')\n",
    "\n",
    "    C_max = max([machine.C for machine in solution])\n",
    "    print(f'\\nThe maximum makespan is C_max: {C_max}')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLUTION FEASIBILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_feasibility(solution, job_dash):\n",
    "        \n",
    "    # def assess_feasibility(solution, job_dash):\n",
    "        # Assesses whether a solution to the problem is feasible or unfeasible. Along with this condition, the function returns:\n",
    "            # If feasible, sol_cost = sol_Cmax.\n",
    "            # If unfeasible, sol_cost = sol_Cmax + (e_time_prec - s_time_dep) + abs(np.sum(acc_res - Rmax_res)).\n",
    "\n",
    "    ############################ DEPENDENCIES ############################\n",
    "\n",
    "    sol_Cmax = max([machine.C for machine in solution])\n",
    "    res_matrix = np.zeros(shape=(M,sol_Cmax))\n",
    "    sol_cost = sol_Cmax\n",
    "\n",
    "    prec_ok = True\n",
    "        \n",
    "    # search of dependencies based on dep_dash\n",
    "        # For the dependent job:\n",
    "            # We find the machine where it was scheduled, and the time when it starts.\n",
    "        # For the precedent job:\n",
    "            # We find the machine where it was scheduled, and the time when it ends.\n",
    "        # We check whether the dependent job starts no sooner than the precedent job has finished.\n",
    "        # If that is not the case, we label the solution as unfeasible and calculate a penalty cost.\n",
    "\n",
    "    for dep_job_idx, prec_job_idx in dep_dash.items():\n",
    "        \n",
    "        # Dependent job information\n",
    "        dep_machine_idx = job_dash.get(dep_job_idx)\n",
    "        dep_machine = solution[dep_machine_idx]\n",
    "        s_time_dep = dep_machine.t_spans.get(dep_job_idx)[0]\n",
    "        \n",
    "        # Precedent job information\n",
    "        prec_machine_idx = job_dash.get(prec_job_idx)\n",
    "        prec_machine = solution[prec_machine_idx]\n",
    "        e_time_prec = prec_machine.t_spans.get(prec_job_idx)[1]\n",
    "        \n",
    "        if s_time_dep < e_time_prec:\n",
    "            prec_ok = False\n",
    "            sol_cost += (e_time_prec - s_time_dep)\n",
    "            break\n",
    "\n",
    "    ############################ RESOURCES ############################\n",
    "    \n",
    "    # Resource requirements are analysed:\n",
    "        # Cumulative use of resources in all machines at every instant of time is calculated.\n",
    "        # The res_ok condition is set to False as soon as Rmax is exceeded.\n",
    "        \n",
    "    for machine in solution:\n",
    "        res_matrix[machine.index, :machine.C] = np.transpose(machine.job_res)    \n",
    "    \n",
    "    acc_res = np.sum(res_matrix, axis=0)\n",
    "    Rmax_res = Rmax*np.ones_like(acc_res)\n",
    "    res_ok = True if np.all(acc_res <= Rmax) else False\n",
    "    sol_cost += 0 if res_ok else abs(np.sum(acc_res - Rmax_res))\n",
    "    \n",
    "    return int(sol_cost), prec_ok, res_ok\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpwtaRQIFYvO"
   },
   "source": [
    "# CONSTRUCTIVE PHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_rcl(pre_sol, job_list, rule, alpha):\n",
    "\n",
    "    # def construct_rcl(pre_sol, job_dict, rule, alpha):\n",
    "        # It constructs a restricted candidate list (RCL).\n",
    "        # Pending jobs are sorted on every machine according to their cost value.\n",
    "    \n",
    "    rcl_dict = {}\n",
    "    _ = [rcl_dict.update({m: []}) for m in range(M)]\n",
    "    \n",
    "    c_list = []\n",
    "\n",
    "    # Assign jobs to machines where the cost is minimum.\n",
    "        # To solve situations in which the cost is minimum on more than one machine, we always use random.choice.\n",
    "        # This solution randomises the deterministic behaviour of np.argmin which alwais assigned the job to the first machine in case of a tie.\n",
    "\n",
    "    for job in job_list:\n",
    "        job_cost_min = min(job.cost)\n",
    "        job_cost_min_idx = [m for m in range(M) if job.cost[m]==job_cost_min]\n",
    "        m = random.choice(job_cost_min_idx)\n",
    "        rcl_dict[m].append(job)\n",
    "        c_list.append(job.cost[m])\n",
    "\n",
    "    cost_min = min(c_list)\n",
    "    cost_max = max(c_list)\n",
    "    \n",
    "    match rule:\n",
    "    \n",
    "        case 'SPT' | 'LRR' | 'DJP' | 'LRR-SPT-IDM' | 'LRR-LPT-IDM':\n",
    "            for m in range(M):\n",
    "                rcl_dict[m].sort(key=lambda x: x.cost[m], reverse=False)\n",
    "\n",
    "            range_start = cost_min\n",
    "            range_end = cost_min + alpha * (cost_max- cost_min)\n",
    "    \n",
    "            # Pending jobs outside the limits of the RCL are removed.\n",
    "        \n",
    "            for m, job_list in rcl_dict.items():\n",
    "                L = len(job_list)-1\n",
    "                for j in range(L, -1, -1):\n",
    "                    if job_list[j].cost[m] > range_end:\n",
    "                        job_list.pop()\n",
    "                    else:\n",
    "                        break\n",
    "                rcl_dict.update({m : job_list})\n",
    "\n",
    "        case 'LPT' | 'MRR' | 'IJP' | 'IDM' | 'MRR-SPT-IDM' | 'MRR-LPT-IDM':\n",
    "            for m in range(M):\n",
    "                rcl_dict[m].sort(key=lambda x: x.cost[m], reverse=True)\n",
    "\n",
    "            range_start = cost_max\n",
    "            range_end = cost_max - alpha * (cost_max - cost_min)\n",
    "    \n",
    "            # Pending jobs outside the limits of the RCL are removed.\n",
    "        \n",
    "            for m, job_list in rcl_dict.items():\n",
    "                L = len(job_list)-1\n",
    "                for j in range(L, -1, -1):\n",
    "                    if job_list[j].cost[m] < range_end:\n",
    "                        job_list.pop()\n",
    "                    else:\n",
    "                        break\n",
    "                rcl_dict.update({m : job_list})\n",
    "\n",
    "    return rcl_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tzrkaBS3gmmz"
   },
   "outputs": [],
   "source": [
    "def select_candidate(rcl_dict):\n",
    "    \n",
    "    candidate_machine_index = None\n",
    "    candidate_job_index = None\n",
    "    \n",
    "    candidate_machine_list = [machine_index for machine_index in rcl_dict.keys() if len(rcl_dict[machine_index]) > 0]\n",
    "    candidate_machine_index = random.choice(candidate_machine_list)\n",
    "    candidate_job_index = random.choice(rcl_dict[candidate_machine_index]).index\n",
    "\n",
    "    return candidate_machine_index, candidate_job_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tzrkaBS3gmmz"
   },
   "outputs": [],
   "source": [
    "def construct_initial_solution(job_list, rule, alpha):\n",
    "\n",
    "    # Creation of a dictionary with items defined by:\n",
    "        # keys: indices of the machines\n",
    "        # values: list of jobs sorted by the SPT rule (processing times in non-decreasing order on each machine)    \n",
    "    \n",
    "    job_dict = {}\n",
    "    job_dash = {}\n",
    "\n",
    "    if rule in ['SPT', 'LPT', 'LRR', 'MRR', 'DJP', 'IJP', 'IDM']:\n",
    "        rule_class = 'simple'\n",
    "    elif rule in ['LRR-SPT-IDM', 'LRR-LPT-IDM', 'MRR-SPT-IDM', 'MRR-LPT-IDM']:\n",
    "        rule_class = 'combined'    \n",
    "\n",
    "    match rule_class:\n",
    "\n",
    "        case 'simple':\n",
    "\n",
    "        ############################ SIMPLE ASSIGNMENT RULES ############################\n",
    "    \n",
    "            match rule:\n",
    "    \n",
    "            # The lists generated by the following rules will NOT be reversed: 'SPT', 'LRR', 'DJP'.\n",
    "            # The lists generated by the following rules will be reversed: 'LPT', 'MRR', 'IJP', 'IDM'.\n",
    "            \n",
    "                case 'SPT' | 'LPT':\n",
    "                    # Job's costs are its processing times on every machine\n",
    "                    for job in job_list:\n",
    "                        for m in range(M):                    \n",
    "                            job.cost[m] = job.p_times[m]\n",
    "            \n",
    "                case 'LRR' | 'MRR':\n",
    "                    # Job's costs are its resource consumption on every machine\n",
    "                    for job in job_list:\n",
    "                        for m in range(M):                    \n",
    "                            job.cost[m] = job.res[m]\n",
    "                \n",
    "                case 'DJP' | 'IJP' | 'IDM':\n",
    "                    # Job's costs depend on its position in the dependency lists and on the assignment rule\n",
    "                    reversed_dep_lists = copy.deepcopy(dep_lists)\n",
    "                    flattened_dep_lists = []\n",
    "                    for dep_sublist in reversed_dep_lists:\n",
    "                        dep_sublist.reverse()\n",
    "                        flattened_dep_lists.extend(dep_sublist)\n",
    "\n",
    "                    max_cost = 0\n",
    "                    for job in job_list:\n",
    "                        # Default (DJP): dependent job's costs are its position in the dependency (sub)list; independent job's costs are zero\n",
    "                        if job.index in flattened_dep_lists:\n",
    "                            for dep_sublist in reversed_dep_lists:\n",
    "                                if job.index in dep_sublist:\n",
    "                                    dep_job_pos = dep_sublist.index(job.index)\n",
    "                                    job.cost = dep_job_pos * np.ones(shape=(M,))\n",
    "                                    if dep_job_pos > max_cost:\n",
    "                                        max_cost = dep_job_pos\n",
    "                                    break\n",
    "                        else:\n",
    "                            job.cost = np.zeros(shape=(M,))\n",
    "                    \n",
    "                    if  rule == 'IJP':\n",
    "                        # IJP: dependent job's costs are zero; independent job's costs are one\n",
    "                        for job in job_list:\n",
    "                            job.cost = np.zeros(shape=(M,)) if job.cost[0] > 0 else np.ones(shape=(M,))\n",
    "\n",
    "                    elif rule == 'IDM':\n",
    "                        # IDM: dependent job's costs are its position in the dependency (sub)list; independent job's costs are (max_cost + 1)\n",
    "                        for job in job_list:\n",
    "                            if job.cost[0] == 0:\n",
    "                                job.cost = (max_cost + 1) * np.ones(shape=(M,))\n",
    "\n",
    "        case 'combined':\n",
    "\n",
    "        ############################ COMBINED ASSIGNMENT RULES ############################\n",
    "    \n",
    "            p_time_avg = 0\n",
    "            res_avg = 0\n",
    "            prec_avg = 0\n",
    "                \n",
    "            # Job's costs depend on its position in the dependency lists and on the assignment rule\n",
    "            reversed_dep_lists = copy.deepcopy(dep_lists)\n",
    "            flattened_dep_lists = []\n",
    "            for dep_sublist in reversed_dep_lists:\n",
    "                dep_sublist.reverse()\n",
    "                flattened_dep_lists.extend(dep_sublist)\n",
    "\n",
    "            max_cost = 0\n",
    "            for job in job_list:\n",
    "                # Default (DJP): dependent job's costs are its position in the dependency (sub)list; independent job's costs are zero\n",
    "                if job.index in flattened_dep_lists:\n",
    "                    for dep_sublist in reversed_dep_lists:\n",
    "                        if job.index in dep_sublist:\n",
    "                            dep_job_pos = dep_sublist.index(job.index)\n",
    "                            job.cost = dep_job_pos * np.ones(shape=(M,))\n",
    "                            if dep_job_pos > max_cost:\n",
    "                                max_cost = dep_job_pos\n",
    "                            break\n",
    "                else:\n",
    "                    job.cost = np.zeros(shape=(M,))\n",
    "                    \n",
    "            # IDM: dependent job's costs are its position in the dependency (sub)list; independent job's costs are (max_cost + 1)\n",
    "            for job in job_list:\n",
    "                if job.cost[0] == 0:\n",
    "                    job.cost = (max_cost + 1) * np.ones(shape=(M,))\n",
    "                p_time_avg += np.sum(job.p_times)\n",
    "                res_avg += np.sum(job.res)\n",
    "                prec_avg += np.sum(job.cost)\n",
    "            \n",
    "            p_time_avg += p_time_avg / (J*M)\n",
    "            res_avg += res_avg / (J*M)\n",
    "            prec_avg += prec_avg / (J*M)\n",
    "\n",
    "            res_factor = p_time_avg // res_avg\n",
    "            prec_factor = p_time_avg // prec_avg\n",
    "    \n",
    "            match rule:\n",
    "    \n",
    "            # The lists generated by the following rules will NOT be reversed: 'LRR-SPT-IDM', 'LRR-LPT-IDM'.\n",
    "            # The lists generated by the following rules will be reversed: 'MRR-SPT-IDM', 'MRR-LPT-IDM'.\n",
    "            \n",
    "                case 'LRR-SPT-IDM':\n",
    "                    for j in range(J):\n",
    "                        for m in range(M):\n",
    "                            job_list[j].cost[m] += (res_factor * job_list[j].res[m]) + job_list[j].p_times[m] - (prec_factor * job_list[j].cost[m])\n",
    "            \n",
    "                case 'LRR-LPT-IDM':\n",
    "                    for j in range(J):\n",
    "                        for m in range(M):\n",
    "                            job_list[j].cost[m] += (res_factor * job_list[j].res[m]) - job_list[j].p_times[m] - (prec_factor * job_list[j].cost[m])\n",
    "                \n",
    "                case 'MRR-SPT-IDM':\n",
    "                    for j in range(J):\n",
    "                        for m in range(M):\n",
    "                            job_list[j].cost[m] += (res_factor * job_list[j].res[m]) - job_list[j].p_times[m] + (prec_factor * job_list[j].cost[m])\n",
    "            \n",
    "                case 'MRR-LPT-IDM':\n",
    "                    for j in range(J):\n",
    "                        for m in range(M):\n",
    "                            job_list[j].cost[m] += (res_factor * job_list[j].res[m]) + job_list[j].p_times[m] + (prec_factor * job_list[j].cost[m])\n",
    "\n",
    "    # There are two options to create the initial job_dict:\n",
    "    #     To transfer the complete job_list, and then to assign each job to one machine in the construct_rcl function.\n",
    "    #     To transfer each job to the machine in which its cost is the minimum. This option avoids executing the for loop every time the construct_rcl function is called.\n",
    "    \n",
    "    _ = [job_dict.update({m: copy.deepcopy(job_list)}) for m in range(M)]\n",
    "    pending_job_list = copy.deepcopy(job_list)\n",
    "    \n",
    "    pending_jobs = J\n",
    "    \n",
    "    machine_env = create_machines(M)\n",
    "    _ = [machine.reset() for machine in machine_env]    \n",
    "    \n",
    "    while pending_jobs > 0:\n",
    "        \n",
    "        rcl_dict = construct_rcl(machine_env, pending_job_list, rule, alpha)\n",
    "        candidate_machine_index, candidate_job_index = select_candidate(rcl_dict)\n",
    "        \n",
    "        # Assign the SPT job to the corresponding machine and remove it from the rest\n",
    "        \n",
    "        job_pos = [job.index for job in pending_job_list].index(candidate_job_index) #[0][0]\n",
    "        candidate_job = pending_job_list.pop(job_pos)\n",
    "        machine_env[candidate_machine_index].program_job(candidate_job)\n",
    "        job_dash.update({candidate_job_index : candidate_machine_index})\n",
    "        \n",
    "        pending_jobs -= 1\n",
    "        \n",
    "    initial_Cmax, initial_prec_ok, initial_res_ok  = assess_feasibility(machine_env, job_dash)\n",
    "    initial_feasibility = initial_prec_ok and initial_res_ok\n",
    "    initial_dict = {initial_Cmax : machine_env}\n",
    "\n",
    "    return initial_dict, machine_env, initial_Cmax, initial_prec_ok, initial_res_ok, job_dash\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution(solution):\n",
    "    \n",
    "    # Generate a solution\n",
    "\n",
    "    solution_dict = {}\n",
    "    len_job_seq = []\n",
    "    \n",
    "    for machine in solution:\n",
    "        job_list = [job.index for job in machine.job_seq]\n",
    "        start_times = machine.s_times\n",
    "        job_tuples = [(start_times[i], job_list[i]) for i in range(len(job_list)) if job_list[i] != J]\n",
    "        solution_dict.update({machine.index: job_tuples})\n",
    "        len_job_seq.append(len(job_tuples))\n",
    "        \n",
    "    \n",
    "    for k,v in solution_dict.items():\n",
    "        append_v = np.nan*np.ones(max(len_job_seq) - len(v))\n",
    "        new_v = v + append_v.tolist()\n",
    "        solution_dict.update({k:new_v})\n",
    "        \n",
    "    solution_df = pd.DataFrame.from_dict(solution_dict, orient='columns')\n",
    "    \n",
    "    return solution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAPHICAL AND TEXTUAL OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_solution(summary_df, alpha_values, makespan_columns, rpd_makespan_columns, g_rule, output_path):\n",
    "\n",
    "    columns = ['Feasibility', 'Alpha', 'RPD Cmax']\n",
    "\n",
    "    summary_rpd_df = pd.DataFrame()\n",
    "    for c in range(4, summary_df.shape[1], 4):\n",
    "        column_idx_ls = [3] + [c] + [c+3]\n",
    "        summary_rpd_aux_df = pd.DataFrame(data=summary_df.iloc[:,column_idx_ls])\n",
    "        summary_rpd_aux_df.columns = columns\n",
    "        summary_rpd_df = pd.concat([summary_rpd_df, summary_rpd_aux_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    hue_order=[False, True]\n",
    "    palette = {False: 'red', True: 'green'}\n",
    "    print('\\n\\n')\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(9, 5)) #, sharex=True)\n",
    "\n",
    "    fig_name = 'RPD_' + g_rule\n",
    "    fig.suptitle(fig_name.replace(\"_\", \" \"))\n",
    "    x_values = summary_rpd_df['Alpha'].unique()\n",
    "    x_labels = [round(x_value, 4) for x_value in x_values]\n",
    "    \n",
    "    ax1 = sns.boxplot(data=summary_rpd_df, x='Alpha', y='RPD Cmax', hue=\"Feasibility\", \n",
    "                      hue_order=hue_order,\n",
    "                      palette=palette,\n",
    "                      fill=False, gap=.1, \n",
    "                      ax=ax1,\n",
    "                      showfliers=False)\n",
    "\n",
    "    ax1.set_xlabel('')\n",
    "    ax1.set_xticklabels(x_labels)\n",
    "    ax1.set_ylabel('RPD Cmax')\n",
    "\n",
    "    ax1.legend(\n",
    "        title='Solution feasibility', loc='lower center', bbox_to_anchor=(0.5, -0.5),\n",
    "        ncol=2, fontsize='small'\n",
    "    )    \n",
    "    \n",
    "    ax2 = sns.boxplot(data=summary_rpd_df[summary_rpd_df[\"Feasibility\"]==True], x='Alpha', y='RPD Cmax',\n",
    "                      color='green',\n",
    "                      fill=False, gap=.1, \n",
    "                      ax=ax2,\n",
    "                      showfliers=False)\n",
    "\n",
    "    # Set y-limits with padding\n",
    "    # y_min, y_max = 0, 1\n",
    "    # padding = 0.05 * (y_max - y_min)  # 5% padding above and below\n",
    "    # ax2.set_ylim([y_min - padding, y_max + padding])\n",
    "\n",
    "    ax2.set_xlabel('alpha')\n",
    "    ax2.set_xticklabels(x_labels)\n",
    "    ax2.set_ylabel('RPD Cmax')\n",
    "    \n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    output_fig_path = output_path / (fig_name + '.png')\n",
    "    plt.savefig(output_fig_path)\n",
    "    plt.show()\n",
    "\n",
    "    ############################ LATEX CODE ############################\n",
    "\n",
    "    # summary_rpd_df = pd.DataFrame()\n",
    "    columns_to_latex = ['Size'] + makespan_columns + rpd_makespan_columns\n",
    "    summary_rpd_df = summary_df[summary_df['Feasibility']==True]\n",
    "    summary_rpd_df = summary_rpd_df.loc[:, columns_to_latex]\n",
    "\n",
    "    # cmax_columns_to_latex = ['Size'] + makespan_columns\n",
    "    # summary_cmax_df = summary_df[summary_df['Feasibility']==True]\n",
    "    # summary_cmax_df = summary_cmax_df.loc[:, cmax_columns_to_latex]\n",
    "\n",
    "    # rpd_columns_to_latex = ['Size'] + rpd_makespan_columns\n",
    "    # summary_rpd_df = summary_df[summary_df['Feasibility']==True]\n",
    "    # summary_rpd_df = summary_rpd_df.loc[:, rpd_columns_to_latex]\n",
    "    \n",
    "    job_ls = []\n",
    "    machine_ls = []\n",
    "    for size in summary_rpd_df['Size']:\n",
    "        size_elements = size.split('x')\n",
    "        job_ls.append(size_elements[0]) \n",
    "        machine_ls.append(size_elements[1])\n",
    "\n",
    "    # summary_cmax_df.drop(columns=['Size'], inplace=True)\n",
    "    # summary_cmax_df.insert(loc=0, column='n', value=job_ls)\n",
    "    # summary_cmax_df.insert(loc=0, column='m', value=machine_ls)\n",
    "\n",
    "    summary_rpd_df.drop(columns=['Size'], inplace=True)\n",
    "    summary_rpd_df.insert(loc=0, column='n', value=job_ls)\n",
    "    summary_rpd_df.insert(loc=0, column='m', value=machine_ls)\n",
    "\n",
    "    cmax_tuples = []\n",
    "    rpd_tuples = []\n",
    "    for alpha in alpha_values:\n",
    "        cmax_tuples.append(('Cmax', '$\\\\alpha='+str(alpha)+'$'))\n",
    "        rpd_tuples.append(('RPD Cmax', '$\\\\alpha='+str(alpha)+'$'))\n",
    "    # tuples_to_latex = [('Size', '')] + makespan_tuples + rpd_makespan_tuples\n",
    "    tuples_to_latex = [('n', ''), ('m', '')] + cmax_tuples + rpd_tuples\n",
    "    # print(tuples_to_latex)\n",
    "    # cmax_tuples_to_latex = [('n', ''), ('m', '')] + cmax_tuples\n",
    "    # rpd_tuples_to_latex = [('n', ''), ('m', '')] + rpd_tuples\n",
    "\n",
    "    summary_rpd_df.columns = pd.MultiIndex.from_tuples(tuples_to_latex)\n",
    "    # summary_cmax_df.columns = pd.MultiIndex.from_tuples(cmax_tuples_to_latex)\n",
    "    # summary_rpd_df.columns = pd.MultiIndex.from_tuples(rpd_tuples_to_latex)\n",
    "    print('\\n\\n' + str(' RPD Makespan Summary ').center(124, '#')) # 160\n",
    "    summary_latex_code = summary_rpd_df.to_latex(na_rep='\\\\phantom{0}', \n",
    "                                                 float_format=\"%.2f\", column_format='r'*summary_rpd_df.shape[1], \n",
    "                                                 decimal='.', \n",
    "                                                 multicolumn=True, \n",
    "                                                 multicolumn_format='c', \n",
    "                                                 multirow=False, \n",
    "                                                 index=False)\n",
    "    summary_latex_code = (\n",
    "        \"\\n\" + r\"\\begin{table}[!ht]\"\n",
    "        + \"\\n\" + r\"\\centering\" \n",
    "        + \"\\n\" + r\"\\caption{\" + g_rule +\"}\"\n",
    "        + \"\\n\" + r\"\\label{tab:YYY}\"\n",
    "        + \"\\n\" + r\"\\begin{adjustbox}{max width=\\textwidth}\" \n",
    "        + \"\\n\" + summary_latex_code\n",
    "        + \"\\end{adjustbox}\" \n",
    "        + \"\\n\" + r\"\\end{table}\"\n",
    "    )\n",
    "    print(summary_latex_code)\n",
    "    # cmax_latex_code = summary_cmax_df.to_latex(na_rep='\\\\phantom{0}', \n",
    "    #                                            float_format=\"%.2f\", \n",
    "    #                                            column_format='r'*summary_rpd_df.shape[1], \n",
    "    #                                            decimal='.', \n",
    "    #                                            multicolumn=True, \n",
    "    #                                            multicolumn_format='c', \n",
    "    #                                            multirow=False, \n",
    "    #                                            index=False)\n",
    "    # cmax_latex_code = r\"\\setlength{\\tabcolsep}{2pt}\" + \"\\n\" + cmax_latex_code\n",
    "    # print(cmax_latex_code)\n",
    "    # rpd_latex_code = summary_rpd_df.to_latex(na_rep='\\\\phantom{0}', \n",
    "    #                                          float_format=\"%.2f\", \n",
    "    #                                          column_format='r'*summary_rpd_df.shape[1], \n",
    "    #                                          decimal='.', \n",
    "    #                                          multicolumn=True, \n",
    "    #                                          multicolumn_format='c', \n",
    "    #                                          multirow=False, \n",
    "    #                                          index=False)\n",
    "    # rpd_latex_code = r\"\\setlength{\\tabcolsep}{2pt}\" + \"\\n\" + rpd_latex_code\n",
    "    # print(rpd_latex_code)\n",
    "    del summary_rpd_df, summary_rpd_aux_df #, summary_cmax_df\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN PROGRAM - CONSTRUCTIVE PHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RIXYkDWcfmwd"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the number of the input dataset (0: debug, 1: cal):  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input data path: C:\\Users\\Usuario\\Notebooks\\PhD\\Paper_01\\input_data\\debug\n",
      "\n",
      "Instances: ['006x2_1-10_1_6.txt', '008x2_1-10_1_6.txt', '010x2_1-10_1_6.txt', '050x15_1-10_1_6.txt']\n",
      "\n",
      "\n",
      "##################################################### Greedy rule: SPT #####################################################\n",
      "\n",
      "> alpha = 0.0: ['006x2_1-10_1_6', '008x2_1-10_1_6', '010x2_1-10_1_6', '050x15_1-10_1_6']\n",
      "> alpha = 0.5: ['006x2_1-10_1_6', '008x2_1-10_1_6', '010x2_1-10_1_6', '050x15_1-10_1_6']\n",
      "> alpha = 1.0: ['006x2_1-10_1_6', '008x2_1-10_1_6', '010x2_1-10_1_6', '050x15_1-10_1_6']\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "################################################### RPD Makespan Summary ###################################################\n",
      "\n",
      "\\begin{table}[!ht]\n",
      "\\centering\n",
      "\\caption{SPT}\n",
      "\\label{tab:YYY}\n",
      "\\begin{adjustbox}{max width=\\textwidth}\n",
      "\\begin{tabular}{rrrrrrrr}\n",
      "\\toprule\n",
      "n & m & \\multicolumn{3}{c}{Cmax} & \\multicolumn{3}{c}{RPD Cmax} \\\\\n",
      " &  & $\\alpha=0.0$ & $\\alpha=0.5$ & $\\alpha=1.0$ & $\\alpha=0.0$ & $\\alpha=0.5$ & $\\alpha=1.0$ \\\\\n",
      "\\midrule\n",
      "6 & 2 & \\phantom{0} & \\phantom{0} & 51.00 & \\phantom{0} & \\phantom{0} & 0.00 \\\\\n",
      "8 & 2 & \\phantom{0} & \\phantom{0} & \\phantom{0} & \\phantom{0} & \\phantom{0} & \\phantom{0} \\\\\n",
      "10 & 2 & \\phantom{0} & \\phantom{0} & \\phantom{0} & \\phantom{0} & \\phantom{0} & \\phantom{0} \\\\\n",
      "50 & 15 & \\phantom{0} & \\phantom{0} & \\phantom{0} & \\phantom{0} & \\phantom{0} & \\phantom{0} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{adjustbox}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############################ ALGORITHM CONFIGURATION ############################\n",
    "\n",
    "parent_path = Path.cwd()\n",
    "\n",
    "input_data_path = parent_path / 'input_data'\n",
    "input_debug_path = input_data_path / 'debug'\n",
    "input_cal_path = input_data_path / 'cal'\n",
    "\n",
    "output_data_path = parent_path / 'output_data'\n",
    "output_debug_path = output_data_path / 'debug'\n",
    "output_cal_path = parent_path / 'output_data' / 'cal'\n",
    "\n",
    "output_data_path.mkdir(exist_ok=True)\n",
    "\n",
    "dataset_dict = {0: 'debug', 1: 'cal'}\n",
    "user_input_dataset = int(input('\\nEnter the number of the input dataset (0: debug, 1: cal): '))\n",
    "instance_type = dataset_dict.get(user_input_dataset)\n",
    "input_path = input_data_path / dataset_dict.get(user_input_dataset)\n",
    "output_path = output_data_path / dataset_dict.get(user_input_dataset)\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "instances = [instance.name for instance in sorted(input_path.glob('*.txt'))]\n",
    "\n",
    "print(f'\\nInput data path: {input_path}')\n",
    "print(f'\\nInstances: {instances}')\n",
    "\n",
    "os.chdir(input_path)\n",
    "\n",
    "sol_name = ''\n",
    "instance_sol = {}\n",
    "instance_sol_keys = ['Size', 'Precedences', 'Resources', 'Feasibility', 'Alpha', 'Cmax']\n",
    "\n",
    "greedy_rules = ['SPT']\n",
    "# greedy_rules = ['SPT', 'LPT', 'LRR', 'MRR', 'DJP', 'DJP', 'IDM', 'LRR-SPT-IDM', 'LRR-LPT-IDM', 'MRR-SPT-IDM', 'MRR-LPT-IDM']\n",
    "\n",
    "# user_alpha_steps = int(input('\\nEnter the number of alpha values to be used to generate the restricted candidate list [0, 11]: '))\n",
    "# alpha_values = np.linspace(0,1,user_alpha_steps)\n",
    "\n",
    "# alpha_values = [0.00, 0.05, 0.10, 0.15, 0.20, 0.25, 0.50, 0.75, 1.00]\n",
    "alpha_values = [0.00, 0.50, 1.00]\n",
    "alpha_dict = {}\n",
    "alpha_columns = []\n",
    "makespan_columns = []\n",
    "rpd_makespan_columns = []\n",
    "for i,v in enumerate(alpha_values):\n",
    "    alpha_dict.update({i:v})\n",
    "    alpha_columns.append(f'Alpha (alpha={str(v)})')\n",
    "    makespan_columns.append(f'Cmax (alpha={str(v)})')\n",
    "    rpd_makespan_columns.append(f'RPD Cmax (alpha={str(v)})')\n",
    "\n",
    "for g_rule in greedy_rules:\n",
    "\n",
    "    g_rule_summary_df = pd.DataFrame()\n",
    "\n",
    "    print('\\n\\n' + str(' Greedy rule: ' + g_rule + ' ').center(124, '#')) # 483\n",
    "\n",
    "    for alpha_value in alpha_values:\n",
    "\n",
    "        a_rule_summary_df = pd.DataFrame()\n",
    "\n",
    "        instance_name_list = []\n",
    "        print()\n",
    "\n",
    "        for instance in instances:\n",
    "    \n",
    "            ############################ DATA LOADING ############################\n",
    "    \n",
    "            load_start_time = time.monotonic()\n",
    "            instance_name = instance.rstrip('.txt')\n",
    "            instance_name_list.append(instance_name)\n",
    "            print(f'> alpha = {str(round(alpha_value, 4))}: {instance_name_list}', end='\\r')\n",
    "            problem_df = read_instance(instance)\n",
    "            instance_size = 'x'.join([str(M), str(J)])\n",
    "            load_end_time = time.monotonic()\n",
    "            load_time = (load_end_time - load_start_time)\n",
    "    \n",
    "            ############################ MULTI-START ############################\n",
    "    \n",
    "            random.seed(42)\n",
    "\n",
    "            instance_summary_dict = {'Size': [instance_size] * 4, \n",
    "                                     'Precedences': [False, False, True, True], \n",
    "                                     'Resources': [False, True, False, True],\n",
    "                                     'Feasibility': [False, False, False, True], \n",
    "                                     'Alpha': [alpha_value] * 4}\n",
    "            instance_summary_df = pd.DataFrame.from_dict(instance_summary_dict, 'columns')\n",
    "            instance_df = pd.DataFrame()\n",
    "    \n",
    "            for key in instance_sol_keys:\n",
    "                instance_sol[key] = []\n",
    "    \n",
    "            # Solution dictionaries\n",
    "            sol_dict_f = {} # feasible solution dictionary\n",
    "            sol_dict_u = {} # unfeasible solution dictionary\n",
    "    \n",
    "            # Job dashboards\n",
    "            job_dash_init = {} # job dashboard\n",
    "            job_dash_f = {} # feasible job dashboard\n",
    "            job_dash_u = {} # unfeasible job dashboard\n",
    "\n",
    "            best_job_dash = {} # job dashboard\n",
    "            best_job_dash_f = {} # feasible job dashboard\n",
    "            best_job_dash_u = {} # unfeasible job dashboard\n",
    "\n",
    "            best_grasp_f_dict = {}\n",
    "            best_grasp_u_dict = {}\n",
    "            best_grasp_sol_dict = {}\n",
    "\n",
    "            best_grasp_f_Cmax = np.inf\n",
    "            best_grasp_f_sol = []\n",
    "            best_grasp_f_dict.update({best_grasp_f_Cmax: best_grasp_f_sol})\n",
    "\n",
    "            best_grasp_u_Cmax = np.inf\n",
    "            best_grasp_u_sol = []\n",
    "            best_grasp_u_dict.update({best_grasp_u_Cmax: best_grasp_u_sol})\n",
    "\n",
    "            # Solution output\n",
    "            instance_Cmax = np.inf\n",
    "            instance_sol_df = pd.DataFrame()\n",
    "    \n",
    "            # Iteration counters\n",
    "            grasp_iter = 0\n",
    "    \n",
    "            # Timers\n",
    "            grasp_time = 0\n",
    "            construct_time = 0\n",
    "    \n",
    "            instance_T = float(J * M)\n",
    "            \n",
    "            while grasp_time < instance_T:\n",
    "    \n",
    "                grasp_iter += 1\n",
    "    \n",
    "                ############################ CONSTRUCTIVE PHASE ############################\n",
    "    \n",
    "                construct_start_time = time.monotonic()\n",
    "    \n",
    "                job_list = create_jobs(problem_df)\n",
    "                dict_const, sol_const, Cmax_const, const_prec_ok, const_res_ok, job_dash_init = construct_initial_solution(job_list, g_rule, alpha_value)\n",
    "                initial_feasibility = const_prec_ok and const_res_ok\n",
    "                \n",
    "                sol_values = [instance_size, const_prec_ok, const_res_ok, initial_feasibility, alpha_value, Cmax_const]\n",
    "                for key, value in zip(instance_sol.keys(), sol_values):\n",
    "                    instance_sol[key].append(value)\n",
    "\n",
    "                if (initial_feasibility) and (Cmax_const < best_grasp_f_Cmax):\n",
    "                    best_grasp_f_dict.clear() # Comment this line if the nuimber of feasible solutions should be reduced to one\n",
    "                    best_grasp_f_Cmax = list(dict_const.keys())[0]\n",
    "                    best_grasp_f_dict.update(dict_const)\n",
    "                    best_job_dash_f.update(job_dash_init)\n",
    "                    sol_name = instance_name + '_' + g_rule + str(alpha_value).replace('.','')[:2] + '.csv'\n",
    "                elif (not initial_feasibility) and (Cmax_const < best_grasp_u_Cmax):\n",
    "                    best_grasp_u_dict.clear() # Comment this line if the nuimber of feasible solutions should be reduced to one\n",
    "                    best_grasp_u_Cmax = list(dict_const.keys())[0]\n",
    "                    best_grasp_u_dict.update(dict_const)\n",
    "                    best_job_dash_u.update(job_dash_init)                \n",
    "                \n",
    "                construct_end_time = time.monotonic()\n",
    "                construct_time += (construct_end_time - construct_start_time)\n",
    "                grasp_time += construct_time\n",
    "            \n",
    "            instance_sol_df = pd.DataFrame.from_dict(instance_sol, orient='columns', dtype=None)\n",
    "            instance_info_df = instance_sol_df.groupby(by=['Size', 'Precedences', 'Resources', 'Feasibility', 'Alpha'], as_index=False).describe(include='all')\n",
    "            # Flatten the columns by joining the levels with an underscore:\n",
    "            instance_info_df.columns = ['_'.join(filter(None, col)).strip() for col in instance_info_df.columns]\n",
    "            instance_summary_df = pd.merge(instance_summary_df, instance_info_df, \n",
    "                                           how='left', \n",
    "                                           on=['Size', 'Precedences', 'Resources', 'Feasibility', 'Alpha']\n",
    "                                          ).fillna({'Value': 0})\n",
    "            a_rule_summary_df = pd.concat([a_rule_summary_df, instance_summary_df], axis=0, ignore_index=True)\n",
    "            \n",
    "            ############################ GENERATE SOLUTION ############################\n",
    "    \n",
    "            if sol_name:\n",
    "                instance_sol_df = generate_solution(best_grasp_f_dict.get(best_grasp_f_Cmax))\n",
    "                sol_file_path = os.path.join(output_path, sol_name)\n",
    "                instance_sol_df.to_csv(sol_file_path, sep=';', header=True, index=True, mode='w', decimal=',')\n",
    "            \n",
    "        a_rule_summary_df.drop(columns=['Cmax_mean', 'Cmax_std', 'Cmax_25%', 'Cmax_50%', 'Cmax_75%', 'Cmax_max'], \n",
    "                               inplace=True)\n",
    "        a_rule_summary_df.rename(columns={'Alpha': f'Alpha (alpha={str(alpha_value)})', \n",
    "                                          'Cmax_count': f'Solutions (alpha={str(alpha_value)})', \n",
    "                                          'Cmax_min': f'Cmax (alpha={str(alpha_value)})'}, \n",
    "                                 inplace=True)\n",
    "        a_rule_summary_df[f'RPD Cmax (alpha={str(alpha_value)})'] = np.nan*np.ones_like(a_rule_summary_df.iloc[:,-1].values)\n",
    "\n",
    "        if g_rule_summary_df.empty:\n",
    "            g_rule_summary_df = pd.DataFrame(a_rule_summary_df)\n",
    "        else:\n",
    "            g_rule_summary_df = pd.merge(g_rule_summary_df, a_rule_summary_df, \n",
    "                                         how='inner', \n",
    "                                         on=['Size', 'Precedences', 'Resources', 'Feasibility'])\n",
    "        \n",
    "    ############################ FINAL EVALUATION ############################\n",
    "\n",
    "    os.chdir(output_path)\n",
    "    output_name = instance_type + '_' + g_rule + '.csv'\n",
    "    output_file_path = output_path / output_name\n",
    "\n",
    "    summary_rpd_df = g_rule_summary_df.copy(deep=True)\n",
    "    \n",
    "    for group_values, group_idx in summary_rpd_df.groupby(by=[\"Size\", \"Feasibility\"]).groups.items():\n",
    "        makespan_inst = summary_rpd_df.loc[group_idx, makespan_columns]\n",
    "        makespan_min = np.nanmin(makespan_inst)\n",
    "        for makespan_column, rpd_makespan_column in zip(makespan_columns, rpd_makespan_columns):\n",
    "            summary_rpd_df.loc[group_idx, rpd_makespan_column] = round((summary_rpd_df.loc[group_idx, makespan_column] - makespan_min) / makespan_min * 100, 4)\n",
    "\n",
    "    output_solution(summary_rpd_df, alpha_values, makespan_columns, rpd_makespan_columns, g_rule, output_path)\n",
    "    summary_rpd_df.drop(columns=alpha_columns, inplace=True)\n",
    "    summary_rpd_df.to_csv(output_file_path, float_format='%.4f', sep=';', header=True, index=False, mode='w', decimal=',')\n",
    "\n",
    "    del instance_summary_df, a_rule_summary_df, g_rule_summary_df, summary_rpd_df\n",
    "    \n",
    "    os.chdir(input_path)\n",
    "    \n",
    "os.chdir(parent_path)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
